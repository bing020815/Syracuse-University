{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Homework 1  \n",
    "\n",
    "Comparing Corpora with Corpus Statistics.  \n",
    "\n",
    "For this homework, select or make two documents.  You can use books from the Gutenberg project already provided by NLTK, the corpora in the nltk.book package, you can choose large documents of your own, or you can put together groups of smaller documents to make two large documents out of the corpora.  \n",
    "\n",
    "Try to pick two documents that are different in character in some aspect:  generally either topic, style, genre or some cultural aspect.  The work in this assignment is to run word frequencies, bigram frequencies and mutual information scores on the two documents.  Then you will select items from these lists to make a comparison between the documents to answer some question about the differences or similarities between them.  \n",
    "\n",
    "1.  Choosing the data:  either  \n",
    "a)\tChoose existing large documents from NLTK or from the Gutenberg collection on the web, or  \n",
    "b)\tCollect your own data, by using your own documents or collecting data from other sources.  Combine the text from these   sources to make two documents for the corpora for the first task.  Describe the method that you used to define and collect the data, including the difference between the documents.  Note any limitations to the method or the text that you were able to find.  Do preprocessing to get the text in a suitable format for processing and describe what you did.  \n",
    "\n",
    "2.  Examine the text in the documents that you chose and decide how to process the words, i.e. decide on tokenization and whether to use all lower case, stopwords or lemmatization.  Using the process developed in the lab,   \n",
    " * list the top 50 words by frequency (normalized by the length of the document)  -- `L1 Normalization`\n",
    " * list the top 50 bigrams by frequencies, and  \n",
    " * list the top 50 bigrams by their Mutual Information scores (using min frequency 5)    \n",
    "\n",
    "Note that you may wish to modify the stop word list, based on your question in Task 3.  To complete this part:  \n",
    "a)\tBriefly state why you chose the processing options that you did.  \n",
    "b)\tAre there any problems with the word or bigram lists that you found? Could you get a better list of bigrams?   \n",
    "c)\tHow are the top 50 bigrams by frequency different from the top 50 bigrams scored by Mutual Information?  \n",
    "d)\tIf you modify the stop word list, or expand the methods of filtering, describe that here.  \n",
    "e)\tYou may choose to also run top trigram lists, and include them in the analysis in part 3.  \n",
    "\n",
    "3. Describe a problem or question that is based on the difference between the two documents.  In the case of literary works, for example, this could be how to characterize the style between two authors or two works of different classes.  Another example would be to compare the informal text in blogs with more formal text.  Or you can do a topic related comparison that selects words (as in the SOTU speeches example).  You could also make a comparison of similar text but at two different times.   \n",
    "\n",
    "Now answer the question you have chosen by giving a discussion of the comparison of the texts.  Using one or more of the types of measures that you ran in the first task, i.e. word frequencies, bigram frequencies, or bigram mutual information, make a comparison of the two documents to answer the problem or question.  For this analysis, you will want to choose or to revise data that will be applicable for your question. You may wish to hand pick out particular examples of word frequencies, bigram frequencies or mutual information scores that contribute evidence for your comparison, or combine examples into categories.    \n",
    "\n",
    "Make sure you include the following in your report:  \n",
    "a)\tClearly describe the problem or question you are trying to address through the comparison between the two selected documents.  \n",
    "b)\tPresent and explain insights or conclusions based on the comparison to answer the question (do not just report numbers)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Hierarchy | Explanation|\n",
    "|:--|:--|\n",
    "|Token | word/vocaburary|\n",
    "|Document | A string consist of a set of tokens|\n",
    "|Corpus | A set of documents|\n",
    "|Corpora | A set of corpus|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|NLTK Methods | Syntax | Explanation|\n",
    "|:--|:--|:--|\n",
    "|regexp_tokenize | (raw_text, pattern) | `raw_text` is a string representing a document and `pattern` is a string representing the regex pattern you wish to apply|\n",
    "|FreqDist | (tokens)| `tokens` is a list of tokens|\n",
    "|most_common() | FreqDist(tokens).most_common(n) | Return a list of the `n` most common elements and their counts from the most common to the least|\n",
    "|bigram | nltk.bigrams(tokens) | `tokens` is a list of tokens|\n",
    "|apply_freq_filter| (frequency) | `frequency` is the minimum amount of times that a token must appear|\n",
    "|bigram_measures |nltk.collocations.BigramAssocMeasures() | A collection of bigram association measures.|\n",
    "|BigramCollocationFinder | | A tool for the finding and ranking of bigram collocations or other association measures. It is often useful to use from_words() rather than constructing an instance directly.|\n",
    "|score_ngrams |BigramCollocationFinder.score_ngrams(bigram_measures,raw_freq ) | Returns the score for a given bigram using the given scoring function. Returns a list of bigrams and their associated normalized frequency distribution.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import FreqDist\n",
    "nltk.corpus.gutenberg.fileids( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shakespeare-hamlet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the text of the book, `Hamlet from William Shakespeare`, from the Gutenberg corpus, tokenize it, and reduce the tokens to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The Tragedie of Hamlet by William Shakespeare 1599]\n",
      "\n",
      "\n",
      "Actus Primus. Scoena Prima.\n",
      "\n",
      "Enter Barnardo and Francisco two Centinels.\n",
      "\n",
      "  Barnardo. Who's there?\n",
      "  Fran. Nay answer me: Stand & vnfold\n",
      "your selfe\n",
      "\n",
      "   Bar. Long liue the King\n",
      "\n",
      "   Fran. Barnardo?\n",
      "  Bar. He\n",
      "\n",
      "   Fran. You come most carefully vpon your houre\n",
      "\n",
      "   Bar. 'Tis now strook twelue, get thee to bed Francisco\n",
      "\n",
      "   Fran. For this releefe much thankes: 'Tis bitter cold,\n",
      "And I am sicke at heart\n",
      "\n",
      "   Barn. Haue you had quiet Guard?\n",
      "  Fran. Not\n"
     ]
    }
   ],
   "source": [
    "# The book filename\n",
    "hamlet = nltk.corpus.gutenberg.fileids( )[15]\n",
    "\n",
    "# Raw text of the book \n",
    "hamlettext = nltk.corpus.gutenberg.raw(hamlet)\n",
    "print(hamlettext[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to lowercase\n",
    "hamlet_text_lower = hamlettext.lower()\n",
    "hamlet_tokens = nltk.word_tokenize(hamlet_text_lower) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 36380 words in the book of Hamlet from William Shakespeare\n"
     ]
    }
   ],
   "source": [
    "print('There are {} words in the book of Hamlet from William Shakespeare'.format(len(hamlet_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 2892),\n",
       " ('.', 1877),\n",
       " ('the', 993),\n",
       " ('and', 862),\n",
       " ('to', 683),\n",
       " ('of', 610),\n",
       " (':', 566),\n",
       " ('i', 559),\n",
       " ('you', 527),\n",
       " ('my', 502),\n",
       " ('a', 497),\n",
       " ('?', 459),\n",
       " ('it', 419),\n",
       " ('in', 388),\n",
       " ('that', 376),\n",
       " ('is', 372),\n",
       " ('ham', 337),\n",
       " ('not', 327),\n",
       " (';', 298),\n",
       " ('his', 285),\n",
       " ('this', 275),\n",
       " ('with', 254),\n",
       " ('your', 253),\n",
       " ('but', 249),\n",
       " ('for', 243),\n",
       " ('me', 228),\n",
       " ('what', 211),\n",
       " ('lord', 211),\n",
       " ('as', 205),\n",
       " ('he', 202),\n",
       " (\"'d\", 200),\n",
       " ('be', 191),\n",
       " ('so', 189),\n",
       " ('him', 178),\n",
       " ('haue', 175),\n",
       " ('king', 172),\n",
       " ('will', 149),\n",
       " ('no', 137),\n",
       " ('our', 130),\n",
       " ('we', 128),\n",
       " ('on', 123),\n",
       " ('are', 121),\n",
       " (\"'s\", 119),\n",
       " ('if', 111),\n",
       " ('all', 109),\n",
       " ('then', 108),\n",
       " ('shall', 107),\n",
       " ('by', 105),\n",
       " ('come', 104),\n",
       " ('let', 104)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a frequency distribution of words - dictionary\n",
    "fdist = FreqDist(hamlet_tokens)\n",
    "fdist.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 337 matches:\n",
      " now my cosin hamlet , and my sonne ? ham . a little more then kin , and lesse \n",
      "t that the clouds still hang on you ? ham . not so my lord , i am too much i'th\n",
      " passing through nature , to eternity ham . i madam , it is common queen . if i\n",
      "why seemes it so particular with thee ham . seemes madam ? nay , it is : i know\n",
      "e stay with vs , go not to wittenberg ham . i shall in all my best obey you mad\n",
      ". come away . exeunt . manet hamlet . ham . oh that this too too solid flesh , \n",
      "cellus . hor . haile to your lordship ham . i am glad to see you well : horatio\n",
      "my lord , and your poore seruant euer ham . sir my good friend , ile change tha\n",
      "oratio ? marcellus mar . my good lord ham . i am very glad to see you : good eu\n",
      ". a truant disposition , good my lord ham . i would not haue your enemy say so \n",
      ", i came to see your fathers funerall ham . i pray thee doe not mock me ( fello\n",
      "ndeed my lord , it followed hard vpon ham . thrift thrift horatio : the funeral\n",
      "ee my father hor . oh where my lord ? ham . in my minds eye ( horatio ) hor . i\n",
      "i saw him once ; he was a goodly king ham . he was a man , take him for all in \n",
      "lord , i thinke i saw him yesternight ham . saw ? who ? hor . my lord , the kin\n",
      " hor . my lord , the king your father ham . the king my father ? hor . season y\n",
      "these gentlemen , this maruell to you ham . for heauens loue let me heare hor .\n",
      "ather : these hands are not more like ham . but where was this ? mar . my lord \n",
      "rd vpon the platforme where we watcht ham . did you not speake to it ? hor . my\n",
      "ast away , and vanisht from our sight ham . tis very strange hor . as i doe liu\n",
      "wne in our duty to let you know of it ham . indeed , indeed sirs ; but this tro\n",
      "atch to night ? both . we doe my lord ham . arm 'd , say you ? both . arm 'd , \n",
      "d , say you ? both . arm 'd , my lord ham . from top to toe ? both . my lord , \n",
      "? both . my lord , from head to foote ham . then saw you not his face ? hor . o\n",
      "yes , my lord , he wore his beauer vp ham . what , lookt he frowningly ? hor . \n"
     ]
    }
   ],
   "source": [
    "# check the sentence that contains the word \n",
    "nltk.Text(hamlet_tokens).concordance(\"ham\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of the analysis:\n",
    "* There are many tokens that are non-alphabatic characters   \n",
    "* Some of the stopwords need to be removed; ex: the, a, so, ...etc\n",
    "* Role names appear a lot and they are not useful to compare tow plays\n",
    "\n",
    "#### Strategies:\n",
    "* alpha_filter function to remove non-alphabatic tokens\n",
    "* remove stopwords with nltk stopwords, new stopwords such as: 'thou', 'thee', 'thy'\n",
    "* remove character's name for the play"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### non-alphabatic tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove the non-alphabatic characters, build a user define function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes a word and returns true if it consists only of non-alphabetic characters\n",
    "def alpha_filter(w):\n",
    "    '''\n",
    "    Expect: string consists of alphabetic characters and non-alphabetic characters, ex: '[', 'the', 'tragedie'\n",
    "    Modifies: match the word that consists only of non-alphabetic characters, ex: '['\n",
    "    Returns: True while there is a match; otherwise, it returns false\n",
    "    '''\n",
    "    import re\n",
    "  # pattern to match word of non-alphabetical characters\n",
    "    pattern = re.compile('^[^a-z]+$')  # from start to the end, there are no alphabatic characters\n",
    "    if (pattern.match(w)):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test alpha_filter function \n",
    "alpha_filter(\"'s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before counts: 36380\n",
      "Before filtering : \n",
      "['[', 'the', 'tragedie', 'of', 'hamlet', 'by', 'william', 'shakespeare', '1599', ']', 'actus', 'primus', '.', 'scoena', 'prima', '.', 'enter', 'barnardo', 'and', 'francisco', 'two', 'centinels', '.', 'barnardo', '.', 'who', \"'s\", 'there', '?', 'fran', '.', 'nay', 'answer', 'me', ':', 'stand', '&', 'vnfold', 'your', 'selfe', 'bar', '.', 'long', 'liue', 'the', 'king', 'fran', '.', 'barnardo', '?', 'bar', '.', 'he', 'fran', '.', 'you', 'come', 'most', 'carefully', 'vpon', 'your', 'houre', 'bar', '.', \"'t\", 'is', 'now', 'strook', 'twelue', ',', 'get', 'thee', 'to', 'bed', 'francisco', 'fran', '.', 'for', 'this', 'releefe', 'much', 'thankes', ':', \"'t\", 'is', 'bitter', 'cold', ',', 'and', 'i', 'am', 'sicke', 'at', 'heart', 'barn', '.', 'haue', 'you', 'had', 'quiet']\n",
      "\n",
      "After counts: 30055\n",
      "After filtering : \n",
      "['the', 'tragedie', 'of', 'hamlet', 'by', 'william', 'shakespeare', 'actus', 'primus', 'scoena', 'prima', 'enter', 'barnardo', 'and', 'francisco', 'two', 'centinels', 'barnardo', 'who', \"'s\", 'there', 'fran', 'nay', 'answer', 'me', 'stand', 'vnfold', 'your', 'selfe', 'bar', 'long', 'liue', 'the', 'king', 'fran', 'barnardo', 'bar', 'he', 'fran', 'you', 'come', 'most', 'carefully', 'vpon', 'your', 'houre', 'bar', \"'t\", 'is', 'now', 'strook', 'twelue', 'get', 'thee', 'to', 'bed', 'francisco', 'fran', 'for', 'this', 'releefe', 'much', 'thankes', \"'t\", 'is', 'bitter', 'cold', 'and', 'i', 'am', 'sicke', 'at', 'heart', 'barn', 'haue', 'you', 'had', 'quiet', 'guard', 'fran', 'not', 'a', 'mouse', 'stirring', 'barn', 'well', 'goodnight', 'if', 'you', 'do', 'meet', 'horatio', 'and', 'marcellus', 'the', 'riuals', 'of', 'my', 'watch', 'bid']\n",
      "\n",
      "Number of words reduced: 6325\n"
     ]
    }
   ],
   "source": [
    "# apply the function to hamlet_tokens\n",
    "\n",
    "# Before\n",
    "print('Before counts: {}'.format(len(hamlet_tokens)))\n",
    "print('Before filtering : \\n{}\\n'.format(hamlet_tokens[:100]))\n",
    "\n",
    "\n",
    "# After\n",
    "# store word in a list comprehension when the condition is ture (word that not consists only of non-alphabetic characters)\n",
    "alph_hamlet_words = [w for w in hamlet_tokens if not alpha_filter(w)] \n",
    "print('After counts: {}'.format(len(alph_hamlet_words)))\n",
    "print('After filtering : \\n{}\\n'.format(alph_hamlet_words[:100]))\n",
    "\n",
    "# Summary\n",
    "print('Number of words reduced: {}'.format(len(hamlet_tokens)-len(alph_hamlet_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 993),\n",
       " ('and', 862),\n",
       " ('to', 683),\n",
       " ('of', 610),\n",
       " ('i', 559),\n",
       " ('you', 527),\n",
       " ('my', 502),\n",
       " ('a', 497),\n",
       " ('it', 419),\n",
       " ('in', 388),\n",
       " ('that', 376),\n",
       " ('is', 372),\n",
       " ('ham', 337),\n",
       " ('not', 327),\n",
       " ('his', 285),\n",
       " ('this', 275),\n",
       " ('with', 254),\n",
       " ('your', 253),\n",
       " ('but', 249),\n",
       " ('for', 243),\n",
       " ('me', 228),\n",
       " ('what', 211),\n",
       " ('lord', 211),\n",
       " ('as', 205),\n",
       " ('he', 202),\n",
       " (\"'d\", 200),\n",
       " ('be', 191),\n",
       " ('so', 189),\n",
       " ('him', 178),\n",
       " ('haue', 175),\n",
       " ('king', 172),\n",
       " ('will', 149),\n",
       " ('no', 137),\n",
       " ('our', 130),\n",
       " ('we', 128),\n",
       " ('on', 123),\n",
       " ('are', 121),\n",
       " (\"'s\", 119),\n",
       " ('if', 111),\n",
       " ('all', 109),\n",
       " ('then', 108),\n",
       " ('shall', 107),\n",
       " ('by', 105),\n",
       " ('come', 104),\n",
       " ('let', 104),\n",
       " ('thou', 104),\n",
       " ('or', 103),\n",
       " ('do', 101),\n",
       " ('hamlet', 100),\n",
       " ('good', 98)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new words freqent distribution\n",
    "FreqDist(alph_hamlet_words).most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of the NLTK stopwords: 179\n",
      "\n",
      "List of the NLTK stopwords: \n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# get a list of stopwords from nltk\n",
    "nltkstopwords = nltk.corpus.stopwords.words('english')\n",
    "print('Number of the NLTK stopwords: {}\\n'.format(len(nltkstopwords)))\n",
    "print('List of the NLTK stopwords: \\n{}'.format(nltkstopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the play of Hamlet, there are 20 more main charactors:\n",
    "\n",
    "|Charactors|Abbrev.| Role|\n",
    "|:--|:--|:--|\n",
    "|Hamlet | Ham | son of the late king and nephew of the present king, Claudius|\n",
    "|Claudius | – | king of Denmark, Hamlet's uncle and brother to the former king|\n",
    "|Gertrude | – | queen of Denmark and Hamlet's mother|\n",
    "|Polonius | Pol/Polon | chief counsellor to the king|\n",
    "|Ophelia | Ophe | Polonius's daughter|\n",
    "|Horatio | Hor/Hora | friend of Hamlet|\n",
    "|Laertes | Laer | Polonius's son|\n",
    "|Voltimand and Cornelius | Volt | courtiers|\n",
    "|Rosencrantz and Guildenstern | Rosin/Guil | courtiers, friends of Hamlet|\n",
    "|Osric | Osr | a courtier|\n",
    "|Marcellus | Mar | an officer|\n",
    "|Barnardo | Bar | an officer|\n",
    "|Francisco | Fran | a soldier|\n",
    "|Reynaldo | Reynol | Polonius's servant|\n",
    "|Ghost | – | the ghost of Hamlet's father|\n",
    "|Fortinbras | Fortin | prince of Norway|\n",
    "|Gravediggers | – | a pair of sextons|\n",
    "|Player King, Player Queen, Lucianus, etc. | King/Qu/kin/Lucian | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 43 matches:\n",
      " his course t ' illume that part of heauen where now it burnes , marcellus and\n",
      "d denmarke did sometimes march : by heauen i charge thee speake mar . it is of\n",
      " it shewes a will most incorrect to heauen , a heart vnfortified , a minde imp\n",
      "t to heart ? fye , 't is a fault to heauen , a fault against the dead , a faul\n",
      " he might not beteene the windes of heauen visit her face too roughly . heauen\n",
      "heauen visit her face too roughly . heauen and earth must i remember : why she\n",
      "l teares . why she , euen she . ( o heauen ! a beast that wants discourse of r\n",
      "; would i had met my dearest foe in heauen , ere i had euer seene that day hor\n",
      "hew me the steepe and thorny way to heauen ; whilst like a puft and recklesse \n",
      "h , my lord , with all the vowes of heauen polon . i , springes to catch woodc\n",
      "amn 'd , bring with thee ayres from heauen , or blasts from hell , be thy euen\n",
      "tten in the state of denmarke hor . heauen will direct it mar . nay , let 's f\n",
      "euer thy deare father loue ham . oh heauen ! gho . reuenge his foule and most \n",
      "gh lewdnesse court it in a shape of heauen : so lust , though to a radiant ang\n",
      "nst thy mother ought ; leaue her to heauen , and to those thornes that in her \n",
      " . enter . ham . oh all you host of heauen ! oh earth ; what els ? and shall i\n",
      "xt with baser matter ; yes yes , by heauen : oh most pernicious woman ! oh vil\n",
      "marcellus . mar . lord hamlet hor . heauen secure him mar . so be it hor . ill\n",
      "ueale it hor . not i , my lord , by heauen mar . nor i , my lord ham . how say\n",
      " welcome . there are more things in heauen and earth , horatio , then are drea\n",
      " polon . with what , in the name of heauen ? ophe . my lord , as i was sowing \n",
      "kings , as oft as any passion vnder heauen , that does afflict our natures . i\n",
      "s ? byrlady your ladiship is neerer heauen then when i saw you last , by the a\n",
      "le the round naue downe the hill of heauen , as low as to the fiends pol . thi\n",
      "aue made milche the burning eyes of heauen , and passion in the gods pol . loo\n"
     ]
    }
   ],
   "source": [
    "# check the sentence that contains the word \n",
    "nltk.Text(hamlet_tokens).concordance(\"heauen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of the updated stopwords: 203\n",
      "\n",
      "List of the updated stopwords: \n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'laer', 'laertes', 'horatio', 'rosin', 'ophe', 'hor', 'ham', 'hamlet', 'qu', 'queene', 'polon', 'pol', \"'s\", 'sha', 'wo', 'y', \"'s\", \"'d\", \"'ll\", \"'t\", \"'m\", \"'re\", \"'ve\", \"n't\"]\n"
     ]
    }
   ],
   "source": [
    "## add some extra stopwords\n",
    "morestopwords = ['laer','laertes','horatio', 'rosin','ophe','hor','ham','hamlet', 'qu', 'queene','polon','pol',\n",
    "                 \"'s\",'sha','wo','y',\"'s\",\"'d\",\"'ll\",\"'t\",\"'m\",\"'re\",\"'ve\", \"n't\"]\n",
    "stopwords = nltkstopwords + morestopwords\n",
    "print('Number of the updated stopwords: {}\\n'.format(len(stopwords)))\n",
    "print('List of the updated stopwords: \\n{}'.format(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before counts: 30055\n",
      "Before filtering : \n",
      "['the', 'tragedie', 'of', 'hamlet', 'by', 'william', 'shakespeare', 'actus', 'primus', 'scoena', 'prima', 'enter', 'barnardo', 'and', 'francisco', 'two', 'centinels', 'barnardo', 'who', \"'s\", 'there', 'fran', 'nay', 'answer', 'me', 'stand', 'vnfold', 'your', 'selfe', 'bar', 'long', 'liue', 'the', 'king', 'fran', 'barnardo', 'bar', 'he', 'fran', 'you', 'come', 'most', 'carefully', 'vpon', 'your', 'houre', 'bar', \"'t\", 'is', 'now', 'strook', 'twelue', 'get', 'thee', 'to', 'bed', 'francisco', 'fran', 'for', 'this', 'releefe', 'much', 'thankes', \"'t\", 'is', 'bitter', 'cold', 'and', 'i', 'am', 'sicke', 'at', 'heart', 'barn', 'haue', 'you', 'had', 'quiet', 'guard', 'fran', 'not', 'a', 'mouse', 'stirring', 'barn', 'well', 'goodnight', 'if', 'you', 'do', 'meet', 'horatio', 'and', 'marcellus', 'the', 'riuals', 'of', 'my', 'watch', 'bid']\n",
      "\n",
      "After counts: 14776\n",
      "After filtering : \n",
      "['tragedie', 'william', 'shakespeare', 'actus', 'primus', 'scoena', 'prima', 'enter', 'barnardo', 'francisco', 'two', 'centinels', 'barnardo', 'fran', 'nay', 'answer', 'stand', 'vnfold', 'selfe', 'bar', 'long', 'liue', 'king', 'fran', 'barnardo', 'bar', 'fran', 'come', 'carefully', 'vpon', 'houre', 'bar', 'strook', 'twelue', 'get', 'thee', 'bed', 'francisco', 'fran', 'releefe', 'much', 'thankes', 'bitter', 'cold', 'sicke', 'heart', 'barn', 'haue', 'quiet', 'guard', 'fran', 'mouse', 'stirring', 'barn', 'well', 'goodnight', 'meet', 'marcellus', 'riuals', 'watch', 'bid', 'make', 'hast', 'enter', 'marcellus', 'fran', 'thinke', 'heare', 'stand', 'friends', 'ground', 'mar', 'leige-men', 'dane', 'fran', 'giue', 'good', 'night', 'mar', 'farwel', 'honest', 'soldier', 'hath', 'relieu', 'fra', 'barnardo', 'ha', 'place', 'giue', 'goodnight', 'exit', 'fran', 'mar', 'holla', 'barnardo', 'bar', 'say', 'peece', 'bar', 'welcome']\n",
      "\n",
      "Number of words reduced: 15279\n"
     ]
    }
   ],
   "source": [
    "# apply the stopwords to alph_hamlet_words\n",
    "\n",
    "# Before\n",
    "print('Before counts: {}'.format(len(alph_hamlet_words)))\n",
    "print('Before filtering : \\n{}\\n'.format(alph_hamlet_words[:100]))\n",
    "\n",
    "\n",
    "# After\n",
    "# store word in a list comprehension when the condition is ture (word that not consists only of non-alphabetic characters)\n",
    "stopped_alph_hamlet_words = [w for w in alph_hamlet_words if not w in stopwords] \n",
    "print('After counts: {}'.format(len(stopped_alph_hamlet_words)))\n",
    "print('After filtering : \\n{}\\n'.format(stopped_alph_hamlet_words[:100]))\n",
    "\n",
    "# Summary\n",
    "print('Number of words reduced: {}'.format(len(alph_hamlet_words)-len(stopped_alph_hamlet_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lord', 211),\n",
       " ('haue', 175),\n",
       " ('king', 172),\n",
       " ('shall', 107),\n",
       " ('come', 104),\n",
       " ('let', 104),\n",
       " ('thou', 104),\n",
       " ('good', 98),\n",
       " ('thy', 90),\n",
       " ('enter', 85),\n",
       " ('oh', 81),\n",
       " ('like', 77),\n",
       " ('well', 70),\n",
       " ('know', 69),\n",
       " ('would', 68),\n",
       " ('selfe', 66),\n",
       " ('may', 65),\n",
       " ('loue', 65),\n",
       " ('sir', 62),\n",
       " ('vs', 61),\n",
       " ('giue', 59),\n",
       " ('thee', 58),\n",
       " ('ile', 58),\n",
       " ('must', 58),\n",
       " ('hath', 57),\n",
       " ('speake', 55),\n",
       " ('make', 54),\n",
       " ('say', 51),\n",
       " ('doe', 51),\n",
       " ('vpon', 50),\n",
       " ('heere', 50),\n",
       " ('father', 50),\n",
       " ('go', 48),\n",
       " ('one', 46),\n",
       " ('see', 46),\n",
       " ('man', 46),\n",
       " ('time', 44),\n",
       " ('mine', 44),\n",
       " ('much', 43),\n",
       " ('heauen', 43),\n",
       " ('tell', 43),\n",
       " ('thinke', 42),\n",
       " ('thus', 41),\n",
       " ('mother', 40),\n",
       " ('play', 40),\n",
       " ('night', 38),\n",
       " ('yet', 37),\n",
       " ('death', 36),\n",
       " ('vp', 35),\n",
       " ('againe', 34)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new words freqent distribution\n",
    "FreqDist(stopped_alph_hamlet_words).most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### list the top 50 words by frequency (normalized by the length of the document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Frequency for top 50 words:\n",
      "\n",
      "lord     :    0.0143\n",
      "haue     :    0.0118\n",
      "king     :    0.0116\n",
      "shall    :    0.0072\n",
      "come     :    0.007\n",
      "let      :    0.007\n",
      "thou     :    0.007\n",
      "good     :    0.0066\n",
      "thy      :    0.0061\n",
      "enter    :    0.0058\n",
      "oh       :    0.0055\n",
      "like     :    0.0052\n",
      "well     :    0.0047\n",
      "know     :    0.0047\n",
      "would    :    0.0046\n",
      "selfe    :    0.0045\n",
      "may      :    0.0044\n",
      "loue     :    0.0044\n",
      "sir      :    0.0042\n",
      "vs       :    0.0041\n",
      "giue     :    0.004\n",
      "thee     :    0.0039\n",
      "ile      :    0.0039\n",
      "must     :    0.0039\n",
      "hath     :    0.0039\n",
      "speake   :    0.0037\n",
      "make     :    0.0037\n",
      "say      :    0.0035\n",
      "doe      :    0.0035\n",
      "vpon     :    0.0034\n",
      "heere    :    0.0034\n",
      "father   :    0.0034\n",
      "go       :    0.0032\n",
      "one      :    0.0031\n",
      "see      :    0.0031\n",
      "man      :    0.0031\n",
      "time     :    0.003\n",
      "mine     :    0.003\n",
      "much     :    0.0029\n",
      "heauen   :    0.0029\n",
      "tell     :    0.0029\n",
      "thinke   :    0.0028\n",
      "thus     :    0.0028\n",
      "mother   :    0.0027\n",
      "play     :    0.0027\n",
      "night    :    0.0026\n",
      "yet      :    0.0025\n",
      "death    :    0.0024\n",
      "vp       :    0.0024\n",
      "againe   :    0.0023\n"
     ]
    }
   ],
   "source": [
    "hamlet_fdist = FreqDist(stopped_alph_hamlet_words)\n",
    "\n",
    "# Total length of the document\n",
    "hamlet_total_word_count = sum(hamlet_fdist.values())\n",
    "\n",
    "print(\"Normalized Frequency for top 50 words:\\n\")\n",
    "for word, count in hamlet_fdist.most_common(50):\n",
    "    normalized_frequency = round((count / hamlet_total_word_count), 4)\n",
    "    print(\"{:8s} :    {:0<.4}\".format(word, normalized_frequency))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### list the top 50 bigrams by frequencies\n",
    "The preprocessed tokens were used to get a list of bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram: \n",
      "['tragedie', 'william', 'shakespeare', 'actus', 'primus', 'scoena', 'prima', 'enter', 'barnardo', 'francisco', 'two', 'centinels', 'barnardo', 'fran', 'nay', 'answer', 'stand', 'vnfold', 'selfe', 'bar']\n",
      "\n",
      "bigram: \n",
      "[('tragedie', 'william'), ('william', 'shakespeare'), ('shakespeare', 'actus'), ('actus', 'primus'), ('primus', 'scoena'), ('scoena', 'prima'), ('prima', 'enter'), ('enter', 'barnardo'), ('barnardo', 'francisco'), ('francisco', 'two'), ('two', 'centinels'), ('centinels', 'barnardo'), ('barnardo', 'fran'), ('fran', 'nay'), ('nay', 'answer'), ('answer', 'stand'), ('stand', 'vnfold'), ('vnfold', 'selfe'), ('selfe', 'bar'), ('bar', 'long')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bigrams and Bigram frequency distribution\n",
    "hamelt_bigrams = list(nltk.bigrams(stopped_alph_hamlet_words))\n",
    "\n",
    "# Summary\n",
    "#unigram\n",
    "print('unigram: \\n{}\\n'.format(stopped_alph_hamlet_words[:20]))\n",
    "#bigram\n",
    "print('bigram: \\n{}\\n'.format(hamelt_bigrams[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('good', 'lord')                 :   23\n",
      "('enter', 'king')                :   16\n",
      "('wee', 'l')                     :   13\n",
      "('haue', 'seene')                :   11\n",
      "('exeunt', 'enter')              :   10\n",
      "('thou', 'hast')                 :    9\n",
      "('haue', 'heard')                :    9\n",
      "('enter', 'polonius')            :    9\n",
      "('lord', 'haue')                 :    9\n",
      "('fathers', 'death')             :    8\n",
      "('let', 'vs')                    :    7\n",
      "('thou', 'art')                  :    7\n",
      "('king', 'haue')                 :    7\n",
      "('would', 'haue')                :    7\n",
      "('set', 'downe')                 :    7\n",
      "('good', 'friends')              :    7\n",
      "('well', 'lord')                 :    7\n",
      "('rosincrance', 'guildensterne') :    7\n",
      "('let', 'see')                   :    7\n",
      "('dost', 'thou')                 :    7\n",
      "('king', 'king')                 :    7\n",
      "('mine', 'owne')                 :    6\n",
      "('king', 'oh')                   :    6\n",
      "('ile', 'haue')                  :    6\n",
      "('let', 'come')                  :    6\n",
      "('sit', 'downe')                 :    5\n",
      "('enter', 'ghost')               :    5\n",
      "('heauen', 'earth')              :    5\n",
      "('lord', 'would')                :    5\n",
      "('let', 'know')                  :    5\n",
      "('lord', 'exeunt')               :    5\n",
      "('wilt', 'thou')                 :    5\n",
      "('tell', 'vs')                   :    5\n",
      "('reynol', 'lord')               :    5\n",
      "('shall', 'heare')               :    5\n",
      "('come', 'come')                 :    5\n",
      "('king', 'shall')                :    5\n",
      "('king', 'polonius')             :    5\n",
      "('get', 'thee')                  :    4\n",
      "('good', 'night')                :    4\n",
      "('marcellus', 'mar')             :    4\n",
      "('thy', 'selfe')                 :    4\n",
      "('father', 'lost')               :    4\n",
      "(\"would'st\", 'thou')             :    4\n",
      "('giue', 'leaue')                :    4\n",
      "('take', 'thy')                  :    4\n",
      "('lord', 'king')                 :    4\n",
      "('mar', 'lord')                  :    4\n",
      "('enter', 'ophelia')             :    4\n",
      "('thy', 'soule')                 :    4\n"
     ]
    }
   ],
   "source": [
    "hamlet_bigrams_fdist = FreqDist(hamelt_bigrams)\n",
    "for words, count in hamlet_bigrams_fdist.most_common(50):\n",
    "    print(\"{:32} : {:4}\".format(str(words), count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### list the top 50 bigrams by their Mutual Information scores (using min frequency 5) \n",
    "The preprocessed tokens were used to get a list of bigrams.\n",
    "\n",
    "Not every pair if words throughout the tokens list will convey large amounts of information. NLTK provides the Pointwise Mutual Information (PMI) scorer object which assigns a statistical metric to compare each bigram. The method also allows you to filter out token pairs that appear less than a minimum amount of times.\n",
    "\n",
    "The pointwise mutual information represents a quantified measure for how much more- or less likely we are to see the two events co-occur, given their individual probabilities, and relative to the case where the two are completely independent.\n",
    "\n",
    "When the pmi is higher, it means that the two words are likely to express a unique concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup for bigrams and bigram measures\n",
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('rosincrance', 'guildensterne'), 9.111428613152404)\n",
      "(('wee', 'l'), 8.644517273515014)\n",
      "(('sit', 'downe'), 8.472456527728708)\n",
      "(('set', 'downe'), 7.498451736261652)\n",
      "(('fathers', 'death'), 7.359115054652763)\n",
      "(('dost', 'thou'), 6.498451736261652)\n",
      "(('wilt', 'thou'), 6.472456527728708)\n",
      "(('heauen', 'earth'), 6.354314068388943)\n",
      "(('enter', 'polonius'), 6.289574121399687)\n",
      "(('exeunt', 'enter'), 6.239943353675086)\n",
      "(('mine', 'owne'), 6.022302722679424)\n",
      "(('thou', 'art'), 5.957883354898948)\n",
      "(('good', 'friends'), 5.7956857154812464)\n",
      "(('haue', 'heard'), 5.762327118534818)\n",
      "(('thou', 'hast'), 5.56556593212019)\n",
      "(('haue', 'seene'), 5.537260562900045)\n",
      "(('enter', 'ghost'), 5.371187886953338)\n",
      "(('tell', 'vs'), 4.815894153604816)\n",
      "(('reynol', 'lord'), 4.751357339021524)\n",
      "(('shall', 'heare'), 4.524538663860136)\n",
      "(('let', 'see'), 4.434321398841936)\n",
      "(('king', 'polonius'), 4.424703396280339)\n",
      "(('good', 'lord'), 4.038721074217058)\n",
      "(('let', 'vs'), 4.027146017336062)\n",
      "(('enter', 'king'), 4.015312460142638)\n",
      "(('lord', 'exeunt'), 3.928235101105603)\n",
      "(('let', 'know'), 3.36393207095054)\n",
      "(('ile', 'haue'), 3.126738544743697)\n",
      "(('would', 'haue'), 3.119649119957373)\n",
      "(('let', 'come'), 3.0350512154214133)\n",
      "(('well', 'lord'), 2.807940867387888)\n",
      "(('come', 'come'), 2.772016809587617)\n",
      "(('king', 'oh'), 2.6698158941168746)\n",
      "(('lord', 'would'), 2.364334215912274)\n",
      "(('king', 'shall'), 2.0051645047665545)\n",
      "(('lord', 'haue'), 1.8485828518852365)\n",
      "(('king', 'king'), 1.805793563635845)\n",
      "(('king', 'haue'), 1.780847206505614)\n"
     ]
    }
   ],
   "source": [
    "# create the bigram finder and score the bigrams by frequency\n",
    "finder = BigramCollocationFinder.from_words(stopped_alph_hamlet_words)\n",
    "finder.apply_freq_filter(5) #remove the word frequency below 5\n",
    "scored = finder.score_ngrams(bigram_measures.pmi)\n",
    "for bscore in scored[:50]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('my', 'lord', 'ham')            :   62\n",
      "('my', 'lord', 'i')              :   18\n",
      "('good', 'my', 'lord')           :   14\n",
      "('i', 'my', 'lord')              :   13\n",
      "('i', 'pray', 'you')             :   12\n",
      "('lord', 'ham', 'i')             :   11\n",
      "('that', 'i', 'haue')            :   11\n",
      "('i', 'can', 'not')              :    9\n",
      "(\"'t\", 'is', 'a')                :    8\n",
      "('my', 'good', 'lord')           :    8\n",
      "('it', 'is', 'a')                :    8\n",
      "('my', 'lord', 'polon')          :    7\n",
      "('lord', 'i', 'haue')            :    7\n",
      "('let', 'me', 'see')             :    7\n",
      "('i', 'haue', 'seene')           :    6\n",
      "('i', 'know', 'not')             :    6\n",
      "('if', 'it', 'be')               :    6\n",
      "('well', 'my', 'lord')           :    6\n",
      "('rosincrance', 'and', 'guildensterne') :    6\n",
      "('you', 'can', 'not')            :    5\n",
      "('it', 'is', 'not')              :    5\n",
      "('ham', 'i', 'am')               :    5\n",
      "('i', 'do', 'not')               :    5\n",
      "('ophe', 'my', 'lord')           :    5\n",
      "('and', 'with', 'a')             :    5\n",
      "('my', 'lord', 'exeunt')         :    5\n",
      "('exeunt', 'enter', 'hamlet')    :    5\n",
      "('lord', 'ham', 'why')           :    5\n",
      "('to', 'the', 'king')            :    5\n",
      "('enter', 'king', 'queene')      :    5\n",
      "('what', 'is', 'the')            :    5\n",
      "('a', 'kinde', 'of')             :    5\n",
      "('my', 'lord', 'you')            :    5\n",
      "('get', 'thee', 'to')            :    4\n",
      "('speake', 'to', 'it')           :    4\n",
      "('what', \"'s\", 'the')            :    4\n",
      "('you', 'for', 'your')           :    4\n",
      "('my', 'lord', 'and')            :    4\n",
      "('hor', 'my', 'lord')            :    4\n",
      "('my', 'lord', 'it')             :    4\n",
      "('i', 'saw', 'him')              :    4\n",
      "('my', 'lord', 'the')            :    4\n",
      "(\"'t\", 'is', 'true')             :    4\n",
      "('by', 'no', 'meanes')           :    4\n",
      "('what', 'i', 'haue')            :    4\n",
      "('you', 'your', 'selfe')         :    4\n",
      "('as', 'it', 'is')               :    4\n",
      "('i', 'doe', 'not')              :    4\n",
      "('let', \"'s\", 'follow')          :    4\n",
      "(\"'t\", 'is', 'not')              :    4\n"
     ]
    }
   ],
   "source": [
    "# trigrams\n",
    "for words, count in FreqDist(nltk.trigrams(alph_hamlet_words)).most_common(50):\n",
    "    print(\"{:32} : {:4}\".format(str(words), count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shakespeare-macbeth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the text of the book, `Macbeth from William Shakespeare`, from the Gutenberg corpus, tokenize it, and reduce the tokens to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The Tragedie of Macbeth by William Shakespeare 1603]\n",
      "\n",
      "\n",
      "Actus Primus. Scoena Prima.\n",
      "\n",
      "Thunder and Lightning. Enter three Witches.\n",
      "\n",
      "  1. When shall we three meet againe?\n",
      "In Thunder, Lightning, or in Raine?\n",
      "  2. When the Hurley-burley's done,\n",
      "When the Battaile's lost, and wonne\n",
      "\n",
      "   3. That will be ere the set of Sunne\n",
      "\n",
      "   1. Where the place?\n",
      "  2. Vpon the Heath\n",
      "\n",
      "   3. There to meet with Macbeth\n",
      "\n",
      "   1. I come, Gray-Malkin\n",
      "\n",
      "   All. Padock calls anon: faire is foule, and foule is faire,\n",
      "Houer through \n"
     ]
    }
   ],
   "source": [
    "# The book filename\n",
    "macbeth = nltk.corpus.gutenberg.fileids( )[16]\n",
    "\n",
    "# Raw text of the book \n",
    "macbethtext = nltk.corpus.gutenberg.raw(macbeth)\n",
    "print(macbethtext[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to lowercase\n",
    "macbeth_text_lower = macbethtext.lower()\n",
    "macbeth_tokens = nltk.word_tokenize(macbeth_text_lower) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 22188 words in the book of Macbeth from William Shakespeare\n"
     ]
    }
   ],
   "source": [
    "print('There are {} words in the book of Macbeth from William Shakespeare'.format(len(macbeth_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 1962),\n",
       " ('.', 1174),\n",
       " ('the', 649),\n",
       " ('and', 545),\n",
       " (':', 477),\n",
       " ('to', 383),\n",
       " ('of', 338),\n",
       " ('i', 331),\n",
       " ('?', 241),\n",
       " ('a', 239),\n",
       " ('that', 236),\n",
       " ('is', 211),\n",
       " ('you', 205),\n",
       " ('my', 203),\n",
       " ('in', 200),\n",
       " (\"'d\", 192),\n",
       " ('not', 185),\n",
       " ('it', 161),\n",
       " ('with', 153),\n",
       " ('his', 146),\n",
       " ('be', 137),\n",
       " ('macb', 137),\n",
       " (\"'s\", 128),\n",
       " ('your', 126),\n",
       " ('our', 123),\n",
       " ('haue', 122),\n",
       " ('but', 120),\n",
       " ('what', 117),\n",
       " ('me', 113),\n",
       " ('he', 112),\n",
       " ('for', 109),\n",
       " ('this', 104),\n",
       " ('all', 100),\n",
       " ('so', 96),\n",
       " ('him', 90),\n",
       " ('as', 89),\n",
       " ('thou', 87),\n",
       " ('we', 83),\n",
       " ('enter', 81),\n",
       " ('which', 80),\n",
       " (\"'\", 74),\n",
       " ('are', 73),\n",
       " ('will', 72),\n",
       " ('they', 70),\n",
       " ('shall', 68),\n",
       " ('no', 67),\n",
       " ('then', 63),\n",
       " ('do', 63),\n",
       " ('macbeth', 62),\n",
       " ('their', 62)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a frequency distribution of words - dictionary\n",
    "fdist = FreqDist(macbeth_tokens)\n",
    "fdist.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no matches\n"
     ]
    }
   ],
   "source": [
    "# check the sentence that contains the word \n",
    "nltk.Text(macbeth_tokens).concordance(\"hor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of the analysis:\n",
    "* There are many tokens that are non-alphabatic characters   \n",
    "* Some of the stopwords need to be removed; ex: the, a, so, ...etc\n",
    "* Role names appear a lot and they are not useful to compare tow plays\n",
    "\n",
    "#### Strategies:\n",
    "* alpha_filter function to remove non-alphabatic tokens\n",
    "* remove stopwords with nltk stopwords, new stopwords such as: 'thou', 'thee', 'thy'\n",
    "* remove chachactors' name for the play"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### non-alphabatic tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove the non-alphabatic characters, build a user define function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes a word and returns true if it consists only of non-alphabetic characters\n",
    "def alpha_filter(w):\n",
    "    '''\n",
    "    Expect: string consists of alphabetic characters and non-alphabetic characters, ex: '[', 'the', 'tragedie'\n",
    "    Modifies: match the word that consists only of non-alphabetic characters, ex: '['\n",
    "    Returns: True while there is a match; otherwise, it returns false\n",
    "    '''\n",
    "    import re\n",
    "  # pattern to match word of non-alphabetical characters\n",
    "    pattern = re.compile('^[^a-z]+$')  # from start to the end, there are no alphabatic characters\n",
    "    if (pattern.match(w)):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test alpha_filter function \n",
    "alpha_filter(\"'s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before counts: 22188\n",
      "Before filtering : \n",
      "['[', 'the', 'tragedie', 'of', 'macbeth', 'by', 'william', 'shakespeare', '1603', ']', 'actus', 'primus', '.', 'scoena', 'prima', '.', 'thunder', 'and', 'lightning', '.', 'enter', 'three', 'witches', '.', '1.', 'when', 'shall', 'we', 'three', 'meet', 'againe', '?', 'in', 'thunder', ',', 'lightning', ',', 'or', 'in', 'raine', '?', '2.', 'when', 'the', 'hurley-burley', \"'s\", 'done', ',', 'when', 'the', 'battaile', \"'s\", 'lost', ',', 'and', 'wonne', '3.', 'that', 'will', 'be', 'ere', 'the', 'set', 'of', 'sunne', '1.', 'where', 'the', 'place', '?', '2.', 'vpon', 'the', 'heath', '3.', 'there', 'to', 'meet', 'with', 'macbeth', '1.', 'i', 'come', ',', 'gray-malkin', 'all', '.', 'padock', 'calls', 'anon', ':', 'faire', 'is', 'foule', ',', 'and', 'foule', 'is', 'faire', ',']\n",
      "\n",
      "After counts: 18049\n",
      "After filtering : \n",
      "['the', 'tragedie', 'of', 'macbeth', 'by', 'william', 'shakespeare', 'actus', 'primus', 'scoena', 'prima', 'thunder', 'and', 'lightning', 'enter', 'three', 'witches', 'when', 'shall', 'we', 'three', 'meet', 'againe', 'in', 'thunder', 'lightning', 'or', 'in', 'raine', 'when', 'the', 'hurley-burley', \"'s\", 'done', 'when', 'the', 'battaile', \"'s\", 'lost', 'and', 'wonne', 'that', 'will', 'be', 'ere', 'the', 'set', 'of', 'sunne', 'where', 'the', 'place', 'vpon', 'the', 'heath', 'there', 'to', 'meet', 'with', 'macbeth', 'i', 'come', 'gray-malkin', 'all', 'padock', 'calls', 'anon', 'faire', 'is', 'foule', 'and', 'foule', 'is', 'faire', 'houer', 'through', 'the', 'fogge', 'and', 'filthie', 'ayre', 'exeunt', 'scena', 'secunda', 'alarum', 'within', 'enter', 'king', 'malcome', 'donalbaine', 'lenox', 'with', 'attendants', 'meeting', 'a', 'bleeding', 'captaine', 'king', 'what', 'bloody']\n",
      "\n",
      "Number of words reduced: 4139\n"
     ]
    }
   ],
   "source": [
    "# apply the function to macbeth_tokens\n",
    "\n",
    "# Before\n",
    "print('Before counts: {}'.format(len(macbeth_tokens)))\n",
    "print('Before filtering : \\n{}\\n'.format(macbeth_tokens[:100]))\n",
    "\n",
    "\n",
    "# After\n",
    "# store word in a list comprehension when the condition is ture (word that not consists only of non-alphabetic characters)\n",
    "alph_macbeth_words = [w for w in macbeth_tokens if not alpha_filter(w)] \n",
    "print('After counts: {}'.format(len(alph_macbeth_words)))\n",
    "print('After filtering : \\n{}\\n'.format(alph_macbeth_words[:100]))\n",
    "\n",
    "# Summary\n",
    "print('Number of words reduced: {}'.format(len(macbeth_tokens)-len(alph_macbeth_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 649),\n",
       " ('and', 545),\n",
       " ('to', 383),\n",
       " ('of', 338),\n",
       " ('i', 331),\n",
       " ('a', 239),\n",
       " ('that', 236),\n",
       " ('is', 211),\n",
       " ('you', 205),\n",
       " ('my', 203),\n",
       " ('in', 200),\n",
       " (\"'d\", 192),\n",
       " ('not', 185),\n",
       " ('it', 161),\n",
       " ('with', 153),\n",
       " ('his', 146),\n",
       " ('be', 137),\n",
       " ('macb', 137),\n",
       " (\"'s\", 128),\n",
       " ('your', 126),\n",
       " ('our', 123),\n",
       " ('haue', 122),\n",
       " ('but', 120),\n",
       " ('what', 117),\n",
       " ('me', 113),\n",
       " ('he', 112),\n",
       " ('for', 109),\n",
       " ('this', 104),\n",
       " ('all', 100),\n",
       " ('so', 96),\n",
       " ('him', 90),\n",
       " ('as', 89),\n",
       " ('thou', 87),\n",
       " ('we', 83),\n",
       " ('enter', 81),\n",
       " ('which', 80),\n",
       " ('are', 73),\n",
       " ('will', 72),\n",
       " ('they', 70),\n",
       " ('shall', 68),\n",
       " ('no', 67),\n",
       " ('then', 63),\n",
       " ('do', 63),\n",
       " ('macbeth', 62),\n",
       " ('their', 62),\n",
       " ('thee', 61),\n",
       " ('vpon', 59),\n",
       " ('on', 59),\n",
       " ('macd', 58),\n",
       " ('from', 57)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new words freqent distribution\n",
    "FreqDist(alph_macbeth_words).most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of the NLTK stopwords: 179\n",
      "\n",
      "List of the NLTK stopwords: \n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# get a list of stopwords from nltk\n",
    "nltkstopwords = nltk.corpus.stopwords.words('english')\n",
    "print('Number of the NLTK stopwords: {}\\n'.format(len(nltkstopwords)))\n",
    "print('List of the NLTK stopwords: \\n{}'.format(nltkstopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the play of Macbeth, there are 20 more main charactors:\n",
    "\n",
    "|Charactors|Abbrev.| Role|\n",
    "|:--|:--|:--|\n",
    "|Duncan | – | king of Scotland|\n",
    "|Malcolm | Malc | Duncan's elder son||\n",
    "|Donalbain | – | Duncan's younger son|\n",
    "|Macbeth | Macb | a general in the army of King Duncan; originally Thane of Glamis, then Thane of Cawdor, and later king of Scotland|\n",
    "|Lady Macbeth | – | Macbeth's wife, and later queen of Scotland|\n",
    "|Banquo | Banq | Macbeth's friend and a general in the army of King Duncan|\n",
    "|Fleance | – | Banquo's son|\n",
    "|Macduff | Macd | Thane of Fife|\n",
    "|Lady Macduff | – | Macduff's wife|\n",
    "|Ross, Lennox, Angus, Menteith, Caithness | Rosse/Lenox/Ang/Ment/Cath | Scottish Thanes|\n",
    "|Siward | – | general of the English forces|\n",
    "|Young Siward | – | Siward's son|\n",
    "|Seyton | – | Macbeth's armourer|\n",
    "|Hecate | – | queen of the witches|\n",
    "|Three Witches| - ||\n",
    "|Captain | Cap | in the Scottish army|\n",
    "|Three Murderers | – | employed by Macbeth|\n",
    "|Two Murderers | – | attack Lady Macduff|\n",
    "|Porter | – | gatekeeper at Macbeth's home|\n",
    "|Doctor | – | Lady Macbeth's doctor||\n",
    "|Doctor | – | at the English court|\n",
    "|Gentlewoman | – | Lady Macbeth's caretaker|\n",
    "|Lord | – | opposed to Macbeth|\n",
    "|First Apparition | – | armed head|\n",
    "|Second Apparition | – | bloody child|\n",
    "|Third Apparition | – | crowned child|\n",
    "|Attendants, Messengers, Servants, Soldiers | – ||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 25 matches:\n",
      " . who comes here ? mal . the worthy thane of rosse lenox . what a haste lookes\n",
      "g king . whence cam'st thou , worthy thane ? rosse . from fiffe , great king , \n",
      "by that most disloyall traytor , the thane of cawdor , began a dismall conflict\n",
      "our generall vse king . no more that thane of cawdor shall deceiue our bosome i\n",
      "1. all haile macbeth , haile to thee thane of glamis 2. all haile macbeth , hai\n",
      "2. all haile macbeth , haile to thee thane of cawdor 3. all haile macbeth , tha\n",
      "ore : by sinells death , i know i am thane of glamis , but how , of cawdor ? th\n",
      "f glamis , but how , of cawdor ? the thane of cawdor liues a prosperous gentlem\n",
      " banq . you shall be king macb . and thane of cawdor too : went it not so ? ban\n",
      "r , he bad me , from him , call thee thane of cawdor : in which addition , hail\n",
      "n which addition , haile most worthy thane , for it is thine banq . what , can \n",
      " the deuill speake true ? macb . the thane of cawdor liues : why doe you dresse\n",
      "n borrowed robes ? ang . who was the thane , liues yet , but vnder heauie iudge\n",
      " ouerthrowne him macb . glamys , and thane of cawdor : the greatest is behinde \n",
      " be kings , when those that gaue the thane of cawdor to me , promis 'd no lesse\n",
      "le you vnto the crowne , besides the thane of cawdor . but 't is strange : and \n",
      "cesse , commencing in a truth ? i am thane of cawdor . if good ? why doe i yeel\n",
      "s from the king , who all-hail 'd me thane of cawdor , by which title before , \n",
      "s . so please you , it is true : our thane is comming : one of my fellowes had \n",
      "nne that morrow see . your face , my thane , is as a booke , where men may read\n",
      "est your ermites king . where 's the thane of cawdor ? we courst him at the hee\n",
      "s it , that thus cry 'd ? why worthy thane , you doe vnbend your noble strength\n",
      "macd . is the king stirring , worthy thane ? macb . not yet macd . he did comma\n",
      "cbeth : beware macduffe , beware the thane of fife : dismisse me . enough . he \n",
      "doct . do you marke that ? lad . the thane of fife , had a wife : where is she \n"
     ]
    }
   ],
   "source": [
    "# check the sentence that contains the word \n",
    "nltk.Text(macbeth_tokens).concordance(\"thane\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of the updated stopwords: 199\n",
      "\n",
      "List of the updated stopwords: \n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'macb', 'macbeth', 'macd', 'banquo', 'lenox', 'mal', 'banq', 'rosse', \"'s\", 'sha', 'wo', 'y', \"'s\", \"'d\", \"'ll\", \"'t\", \"'m\", \"'re\", \"'ve\", \"n't\"]\n"
     ]
    }
   ],
   "source": [
    "## add some extra stopwords\n",
    "morestopwords = ['macb', 'macbeth', 'macd', 'banquo', 'lenox', 'mal','banq','rosse',\n",
    "                 \"'s\",'sha','wo','y',\"'s\",\"'d\",\"'ll\",\"'t\",\"'m\",\"'re\",\"'ve\", \"n't\"]\n",
    "stopwords = nltkstopwords + morestopwords\n",
    "print('Number of the updated stopwords: {}\\n'.format(len(stopwords)))\n",
    "print('List of the updated stopwords: \\n{}'.format(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before counts: 18049\n",
      "Before filtering : \n",
      "['the', 'tragedie', 'of', 'macbeth', 'by', 'william', 'shakespeare', 'actus', 'primus', 'scoena', 'prima', 'thunder', 'and', 'lightning', 'enter', 'three', 'witches', 'when', 'shall', 'we', 'three', 'meet', 'againe', 'in', 'thunder', 'lightning', 'or', 'in', 'raine', 'when', 'the', 'hurley-burley', \"'s\", 'done', 'when', 'the', 'battaile', \"'s\", 'lost', 'and', 'wonne', 'that', 'will', 'be', 'ere', 'the', 'set', 'of', 'sunne', 'where', 'the', 'place', 'vpon', 'the', 'heath', 'there', 'to', 'meet', 'with', 'macbeth', 'i', 'come', 'gray-malkin', 'all', 'padock', 'calls', 'anon', 'faire', 'is', 'foule', 'and', 'foule', 'is', 'faire', 'houer', 'through', 'the', 'fogge', 'and', 'filthie', 'ayre', 'exeunt', 'scena', 'secunda', 'alarum', 'within', 'enter', 'king', 'malcome', 'donalbaine', 'lenox', 'with', 'attendants', 'meeting', 'a', 'bleeding', 'captaine', 'king', 'what', 'bloody']\n",
      "\n",
      "After counts: 9489\n",
      "After filtering : \n",
      "['tragedie', 'william', 'shakespeare', 'actus', 'primus', 'scoena', 'prima', 'thunder', 'lightning', 'enter', 'three', 'witches', 'shall', 'three', 'meet', 'againe', 'thunder', 'lightning', 'raine', 'hurley-burley', 'done', 'battaile', 'lost', 'wonne', 'ere', 'set', 'sunne', 'place', 'vpon', 'heath', 'meet', 'come', 'gray-malkin', 'padock', 'calls', 'anon', 'faire', 'foule', 'foule', 'faire', 'houer', 'fogge', 'filthie', 'ayre', 'exeunt', 'scena', 'secunda', 'alarum', 'within', 'enter', 'king', 'malcome', 'donalbaine', 'attendants', 'meeting', 'bleeding', 'captaine', 'king', 'bloody', 'man', 'report', 'seemeth', 'plight', 'reuolt', 'newest', 'state', 'serieant', 'like', 'good', 'hardie', 'souldier', 'fought', \"'gainst\", 'captiuitie', 'haile', 'braue', 'friend', 'say', 'king', 'knowledge', 'broyle', 'thou', 'didst', 'leaue', 'cap', 'doubtfull', 'stood', 'two', 'spent', 'swimmers', 'doe', 'cling', 'together', 'choake', 'art', 'mercilesse', 'macdonwald', 'worthie', 'rebell', 'multiplying']\n",
      "\n",
      "Number of words reduced: 8560\n"
     ]
    }
   ],
   "source": [
    "# apply the stopwords to alph_hamlet_words\n",
    "\n",
    "# Before\n",
    "print('Before counts: {}'.format(len(alph_macbeth_words)))\n",
    "print('Before filtering : \\n{}\\n'.format(alph_macbeth_words[:100]))\n",
    "\n",
    "\n",
    "# After\n",
    "# store word in a list comprehension when the condition is ture (word that not consists only of non-alphabetic characters)\n",
    "stopped_alph_macbeth_words = [w for w in alph_macbeth_words if not w in stopwords] \n",
    "print('After counts: {}'.format(len(stopped_alph_macbeth_words)))\n",
    "print('After filtering : \\n{}\\n'.format(stopped_alph_macbeth_words[:100]))\n",
    "\n",
    "# Summary\n",
    "print('Number of words reduced: {}'.format(len(alph_macbeth_words)-len(stopped_alph_macbeth_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('haue', 122),\n",
       " ('thou', 87),\n",
       " ('enter', 81),\n",
       " ('shall', 68),\n",
       " ('thee', 61),\n",
       " ('vpon', 59),\n",
       " ('yet', 57),\n",
       " ('thy', 56),\n",
       " ('vs', 56),\n",
       " ('come', 54),\n",
       " ('king', 53),\n",
       " ('hath', 52),\n",
       " ('good', 48),\n",
       " ('lady', 48),\n",
       " ('would', 47),\n",
       " ('time', 46),\n",
       " ('let', 42),\n",
       " ('like', 40),\n",
       " ('say', 39),\n",
       " ('make', 39),\n",
       " ('doe', 38),\n",
       " ('lord', 38),\n",
       " ('must', 36),\n",
       " ('done', 35),\n",
       " ('ile', 35),\n",
       " ('feare', 35),\n",
       " ('wife', 34),\n",
       " ('man', 33),\n",
       " ('well', 33),\n",
       " ('know', 33),\n",
       " ('selfe', 32),\n",
       " ('one', 32),\n",
       " ('great', 31),\n",
       " ('see', 31),\n",
       " ('may', 31),\n",
       " ('exeunt', 30),\n",
       " ('speake', 29),\n",
       " ('night', 29),\n",
       " ('sir', 29),\n",
       " ('mine', 26),\n",
       " ('vp', 26),\n",
       " ('th', 26),\n",
       " ('heere', 26),\n",
       " ('thane', 25),\n",
       " ('giue', 24),\n",
       " ('looke', 23),\n",
       " ('things', 23),\n",
       " ('sleepe', 23),\n",
       " ('hand', 23),\n",
       " ('blood', 23)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new words freqent distribution\n",
    "FreqDist(stopped_alph_macbeth_words).most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### list the top 50 words by frequency (normalized by the length of the document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Frequency for top 50 words:\n",
      "\n",
      "haue     :    0.0083\n",
      "thou     :    0.0059\n",
      "enter    :    0.0055\n",
      "shall    :    0.0046\n",
      "thee     :    0.0041\n",
      "vpon     :    0.004\n",
      "yet      :    0.0039\n",
      "thy      :    0.0038\n",
      "vs       :    0.0038\n",
      "come     :    0.0037\n",
      "king     :    0.0036\n",
      "hath     :    0.0035\n",
      "good     :    0.0032\n",
      "lady     :    0.0032\n",
      "would    :    0.0032\n",
      "time     :    0.0031\n",
      "let      :    0.0028\n",
      "like     :    0.0027\n",
      "say      :    0.0026\n",
      "make     :    0.0026\n",
      "doe      :    0.0026\n",
      "lord     :    0.0026\n",
      "must     :    0.0024\n",
      "done     :    0.0024\n",
      "ile      :    0.0024\n",
      "feare    :    0.0024\n",
      "wife     :    0.0023\n",
      "man      :    0.0022\n",
      "well     :    0.0022\n",
      "know     :    0.0022\n",
      "selfe    :    0.0022\n",
      "one      :    0.0022\n",
      "great    :    0.0021\n",
      "see      :    0.0021\n",
      "may      :    0.0021\n",
      "exeunt   :    0.002\n",
      "speake   :    0.002\n",
      "night    :    0.002\n",
      "sir      :    0.002\n",
      "mine     :    0.0018\n",
      "vp       :    0.0018\n",
      "th       :    0.0018\n",
      "heere    :    0.0018\n",
      "thane    :    0.0017\n",
      "giue     :    0.0016\n",
      "looke    :    0.0016\n",
      "things   :    0.0016\n",
      "sleepe   :    0.0016\n",
      "hand     :    0.0016\n",
      "blood    :    0.0016\n"
     ]
    }
   ],
   "source": [
    "macbeth_fdist = FreqDist(stopped_alph_macbeth_words)\n",
    "\n",
    "# Total length of the document\n",
    "macbeth_total_word_count = sum(hamlet_fdist.values())\n",
    "\n",
    "print(\"Normalized Frequency for top 50 words:\\n\")\n",
    "for word, count in macbeth_fdist.most_common(50):\n",
    "    normalized_frequency = round((count / macbeth_total_word_count), 4)\n",
    "    print(\"{:8s} :    {:0<.4}\".format(word, normalized_frequency))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### list the top 50 bigrams by frequencies\n",
    "The preprocessed tokens were used to get a list of bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram: \n",
      "['tragedie', 'william', 'shakespeare', 'actus', 'primus', 'scoena', 'prima', 'thunder', 'lightning', 'enter', 'three', 'witches', 'shall', 'three', 'meet', 'againe', 'thunder', 'lightning', 'raine', 'hurley-burley']\n",
      "\n",
      "bigram: \n",
      "[('tragedie', 'william'), ('william', 'shakespeare'), ('shakespeare', 'actus'), ('actus', 'primus'), ('primus', 'scoena'), ('scoena', 'prima'), ('prima', 'thunder'), ('thunder', 'lightning'), ('lightning', 'enter'), ('enter', 'three'), ('three', 'witches'), ('witches', 'shall'), ('shall', 'three'), ('three', 'meet'), ('meet', 'againe'), ('againe', 'thunder'), ('thunder', 'lightning'), ('lightning', 'raine'), ('raine', 'hurley-burley'), ('hurley-burley', 'done')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bigrams and Bigram frequency distribution\n",
    "macbeth_bigrams = list(nltk.bigrams(stopped_alph_macbeth_words))\n",
    "\n",
    "# Summary\n",
    "#unigram\n",
    "print('unigram: \\n{}\\n'.format(stopped_alph_macbeth_words[:20]))\n",
    "#bigram\n",
    "print('bigram: \\n{}\\n'.format(macbeth_bigrams[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('exeunt', 'scena')              :   15\n",
      "('thane', 'cawdor')              :   13\n",
      "('knock', 'knock')               :   10\n",
      "('thou', 'art')                  :    9\n",
      "('haue', 'done')                 :    8\n",
      "('enter', 'lady')                :    8\n",
      "('good', 'lord')                 :    8\n",
      "('let', 'vs')                    :    7\n",
      "('wee', 'l')                     :    7\n",
      "('enter', 'three')               :    5\n",
      "('three', 'witches')             :    5\n",
      "('scena', 'secunda')             :    5\n",
      "('enter', 'king')                :    5\n",
      "('worthy', 'thane')              :    5\n",
      "('thy', 'selfe')                 :    5\n",
      "('euery', 'one')                 :    5\n",
      "('would', 'haue')                :    5\n",
      "('mine', 'eyes')                 :    5\n",
      "('make', 'vs')                   :    5\n",
      "('enter', 'malcolme')            :    5\n",
      "('mine', 'owne')                 :    5\n",
      "('ten', 'thousand')              :    4\n",
      "('shew', 'shew')                 :    4\n",
      "('haue', 'seene')                :    4\n",
      "('come', 'come')                 :    4\n",
      "('malcolme', 'donalbaine')       :    4\n",
      "('haile', 'king')                :    4\n",
      "('would', 'make')                :    4\n",
      "('hath', 'made')                 :    4\n",
      "('scena', 'prima')               :    4\n",
      "('see', 'thee')                  :    4\n",
      "('tertia', 'enter')              :    4\n",
      "('old', 'man')                   :    4\n",
      "('enter', 'macduffe')            :    4\n",
      "('thy', 'face')                  :    4\n",
      "('woman', 'borne')               :    4\n",
      "('borne', 'woman')               :    4\n",
      "('king', 'scotland')             :    3\n",
      "('thee', 'thy')                  :    3\n",
      "('enter', 'angus')               :    3\n",
      "('king', 'thane')                :    3\n",
      "('scena', 'tertia')              :    3\n",
      "('thunder', 'enter')             :    3\n",
      "('ile', 'doe')                   :    3\n",
      "('doe', 'ile')                   :    3\n",
      "('giue', 'thee')                 :    3\n",
      "('looke', 'haue')                :    3\n",
      "('weyward', 'sisters')           :    3\n",
      "('looke', 'like')                :    3\n",
      "('haile', 'haile')               :    3\n"
     ]
    }
   ],
   "source": [
    "macbeth_bigrams_fdist = FreqDist(macbeth_bigrams)\n",
    "for words, count in macbeth_bigrams_fdist.most_common(50):\n",
    "    print(\"{:32} : {:4}\".format(str(words), count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### list the top 50 bigrams by their Mutual Information scores (using min frequency 5) \n",
    "The preprocessed tokens were used to get a list of bigrams.\n",
    "\n",
    "Not every pair if words throughout the tokens list will convey large amounts of information. NLTK provides the Pointwise Mutual Information (PMI) scorer object which assigns a statistical metric to compare each bigram. The method also allows you to filter out token pairs that appear less than a minimum amount of times.\n",
    "\n",
    "The pointwise mutual information represents a quantified measure for how much more- or less likely we are to see the two events co-occur, given their individual probabilities, and relative to the case where the two are completely independent.\n",
    "\n",
    "When the pmi is higher, it means that the two words are likely to express a unique concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup for bigrams and bigram measures\n",
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('wee', 'l'), 9.238035549771494)\n",
      "(('three', 'witches'), 8.83352871798482)\n",
      "(('scena', 'secunda'), 8.752608722601252)\n",
      "(('knock', 'knock'), 8.533968436125914)\n",
      "(('thane', 'cawdor'), 7.876306446826158)\n",
      "(('exeunt', 'scena'), 7.752608722601252)\n",
      "(('mine', 'eyes'), 7.374097099347523)\n",
      "(('worthy', 'thane'), 6.890112246351187)\n",
      "(('mine', 'owne'), 6.74606587673448)\n",
      "(('euery', 'one'), 6.533968436125912)\n",
      "(('thou', 'art'), 5.76909684538982)\n",
      "(('enter', 'malcolme'), 5.493678715100195)\n",
      "(('enter', 'three'), 5.493678715100195)\n",
      "(('good', 'lord'), 5.379150327073807)\n",
      "(('let', 'vs'), 4.819722918459789)\n",
      "(('thy', 'selfe'), 4.726613514068308)\n",
      "(('make', 'vs'), 4.44121129520606)\n",
      "(('enter', 'lady'), 4.287227837632768)\n",
      "(('haue', 'done'), 4.152019986730695)\n",
      "(('enter', 'king'), 3.466197978678087)\n",
      "(('would', 'haue'), 3.0486422468853878)\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "# create the bigram finder and score the bigrams by frequency\n",
    "finder = BigramCollocationFinder.from_words(stopped_alph_macbeth_words)\n",
    "finder.apply_freq_filter(5) #remove the word frequency below 5\n",
    "scored = finder.score_ngrams(bigram_measures.pmi)\n",
    "count=0\n",
    "for bscore in scored[:50]:\n",
    "    count+=1\n",
    "    print (bscore)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('thane', 'of', 'cawdor')        :   13\n",
      "('the', 'thane', 'of')           :    8\n",
      "('my', 'good', 'lord')           :    8\n",
      "('i', 'pray', 'you')             :    7\n",
      "('can', 'not', 'be')             :    6\n",
      "('who', \"'s\", 'there')           :    6\n",
      "('knock', 'knock', 'knock')      :    6\n",
      "('i', 'can', 'not')              :    5\n",
      "('enter', 'macbeth', 'macb')     :    5\n",
      "('what', \"'s\", 'the')            :    5\n",
      "('i', 'my', 'good')              :    5\n",
      "('exeunt', 'scena', 'secunda')   :    4\n",
      "('this', 'is', 'the')            :    4\n",
      "('all', 'haile', 'macbeth')      :    4\n",
      "('there', \"'s\", 'no')            :    4\n",
      "('it', 'is', 'a')                :    4\n",
      "('he', 'ha', \"'s\")               :    4\n",
      "('i', 'would', 'not')            :    4\n",
      "('i', 'see', 'thee')             :    4\n",
      "('i', 'haue', 'done')            :    4\n",
      "('good', 'lord', 'macb')         :    4\n",
      "('i', 'will', 'not')             :    4\n",
      "('my', 'lord', 'macb')           :    4\n",
      "('she', 'ha', \"'s\")              :    4\n",
      "('borne', 'of', 'woman')         :    4\n",
      "('to', 'the', 'king')            :    3\n",
      "('king', 'of', 'scotland')       :    3\n",
      "('rosse', 'and', 'angus')        :    3\n",
      "('exeunt', 'scena', 'tertia')    :    3\n",
      "('thunder', 'enter', 'the')      :    3\n",
      "('enter', 'the', 'three')        :    3\n",
      "('the', 'three', 'witches')      :    3\n",
      "('i', 'haue', 'a')               :    3\n",
      "('thee', 'thane', 'of')          :    3\n",
      "('why', 'doe', 'you')            :    3\n",
      "('and', 'to', 'be')              :    3\n",
      "('giue', 'me', 'your')           :    3\n",
      "('exeunt', 'scena', 'quarta')    :    3\n",
      "('but', 'i', 'haue')             :    3\n",
      "('take', 'my', 'leaue')          :    3\n",
      "('me', 'to', 'the')              :    3\n",
      "('to', 'night', 'lady')          :    3\n",
      "('i', 'haue', 'no')              :    3\n",
      "('which', 'would', 'be')         :    3\n",
      "('i', 'dare', 'not')             :    3\n",
      "('now', 'do', \"'s\")              :    3\n",
      "('you', 'haue', 'done')          :    3\n",
      "('scena', 'prima', 'enter')      :    3\n",
      "('with', 'a', 'torch')           :    3\n",
      "('vpon', 'me', 'and')            :    3\n"
     ]
    }
   ],
   "source": [
    "# trigrams\n",
    "for words, count in FreqDist(nltk.trigrams(alph_macbeth_words)).most_common(50):\n",
    "    print(\"{:32} : {:4}\".format(str(words), count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
